{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "awdAXVnGp5-e"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from collections import defaultdict\n",
        "from datetime import datetime, timedelta\n",
        "from glob import glob\n",
        "from math import asin, cos, radians, sin, sqrt\n",
        "from numbers import Real\n",
        "from typing import Any, Iterator, Tuple, Union\n",
        "\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pymysql\n",
        "import rasterio\n",
        "import sshtunnel\n",
        "from numpy import positive\n",
        "from pyproj import Transformer, transform\n",
        "from shapely.geometry import Point, Polygon\n",
        "from sqlalchemy import (\n",
        "    Connection,\n",
        "    CursorResult,\n",
        "    Engine,\n",
        "    Select,\n",
        "    TextClause,\n",
        "    create_engine,\n",
        "    func,\n",
        "    select,\n",
        ")\n",
        "from sqlalchemy.sql.expression import text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gFAsFCREmUhk"
      },
      "outputs": [],
      "source": [
        "timelike = Union[str, Real, datetime, pd.Timestamp]\n",
        "\n",
        "def to_datetime(time: timelike) -> pd.Timestamp:\n",
        "    if isinstance(time, str):\n",
        "        time = pd.Timestamp(time, tz=\"utc\")\n",
        "    elif isinstance(time, datetime):\n",
        "        time = pd.to_datetime(time, utc=True)\n",
        "    elif isinstance(time, Real):\n",
        "        time = pd.Timestamp(float(time), unit=\"s\", tz=\"utc\")\n",
        "    return time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "LAT_MIN, LAT_MAX = 50.896393, 50.967115\n",
        "LON_MIN, LON_MAX = 6.919968, 7.005756\n",
        "ALT_MIN, ALT_MAX = 0, 750 # update from 700 m to 750 m, in line with CTR limit at 2500 ft plus margin (and accounting for Geoid Height)\n",
        "\n",
        "TIME_BETWEEN_TRAJS = 30\n",
        "\n",
        "# SERA.5005(f)(1) criteria\n",
        "ALERT_DISTANCE_M = 600      # alert distance wrt obstacles (should be 600)\n",
        "ALERT_DELTA_HEIGHT_M = 300   # delta height (should be 300)\n",
        "\n",
        "CPA_MARGIN_M = 20 # allowance for lateral distance to obstacle\n",
        "DIP_MARGIN_M = 20 # allowance for dip below minimum height (45m corresponds to GVA = 2)\n",
        "N_MIN = 5\n",
        "\n",
        "GEOID_HEIGHT_M = 47  # geoid height for Cologne\n",
        "\n",
        "sshtunnel.SSH_TIMEOUT = 5.0\n",
        "sshtunnel.TUNNEL_TIMEOUT = 5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA04jyXL_uqQ"
      },
      "source": [
        "# Setup OpenSky Network Trino credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {
        "id": "2EgQ12zo-3lL"
      },
      "outputs": [],
      "source": [
        "OSN_secrets_json = '/Users/patatino/Nextcloud/Documents/Survol/Trino_Access/trino_secrets.json'\n",
        "MYSQL_secrets_json = './mysql_secrets.json'\n",
        "\n",
        "with open(OSN_secrets_json) as OSN_secrets:\n",
        "  OSN_creds = json.load(OSN_secrets)\n",
        "\n",
        "with open(MYSQL_secrets_json) as MYSQL_secrets:\n",
        "  MYSQL_creds = json.load(MYSQL_secrets)\n",
        "\n",
        "os.environ['OPENSKY_USERNAME'] = OSN_creds['OPENSKY_USERNAME']\n",
        "os.environ['OPENSKY_PASSWORD'] = OSN_creds['OPENSKY_PASSWORD']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "OSN_secrets_json = './trino_secrets.json'\n",
        "\n",
        "with open(OSN_secrets_json) as OSN_secrets:\n",
        "  OSN_creds = json.load(OSN_secrets)\n",
        "\n",
        "os.environ['OPENSKY_USERNAME'] = OSN_creds['OPENSKY_USERNAME']\n",
        "os.environ['OPENSKY_PASSWORD'] = OSN_creds['OPENSKY_PASSWORD']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJBLYkVw_8uj"
      },
      "source": [
        "# Test connection with basic SQL query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVXn7KzE9zCm",
        "outputId": "b2e20b4f-c5a5-4dc0-8cb6-86f4b16bd531"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "FINISHED: : 31.8% [00:00, 148%/s] \n",
            "DOWNLOAD: 5.00lines [00:00, 562lines/s]\n"
          ]
        }
      ],
      "source": [
        "from pyopensky.trino import Trino\n",
        "\n",
        "trino = Trino()\n",
        "\n",
        "query = \"select * from state_vectors_data4 limit 5\"\n",
        "\n",
        "df = trino.query(query, cached = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Send queries and merge results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {},
      "outputs": [],
      "source": [
        "start_str = \"01/07/24\"\n",
        "end_str = \"02/07/24\"\n",
        "\n",
        "start = datetime.strptime(start_str, '%d/%m/%y')\n",
        "end = datetime.strptime(end_str, '%d/%m/%y')\n",
        "\n",
        "# Modify start_date to be 00:00:00\n",
        "start = start.replace(hour=0, minute=0, second=1, microsecond=0)\n",
        "# Modify end_date to be 23:59:59\n",
        "end = end.replace(hour=23, minute=59, second=59, microsecond=999999)\n",
        "\n",
        "start_time = int(start.timestamp())\n",
        "start_hour = start_time - (start_time % 3600)\n",
        "end_time = int(end.timestamp())\n",
        "end_hour = end_time - (end_time % 3600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "FINISHED: : 100% [00:11, 9.00%/s] \n",
            "DOWNLOAD: 48.5klines [00:00, 393klines/s]\n"
          ]
        }
      ],
      "source": [
        "svdata4_query = (\n",
        "        f\"SELECT * FROM state_vectors_data4\"\n",
        "        f\" WHERE icao24 LIKE '%'\"\n",
        "        f\" AND time >= {start_time} AND time <= {end_time}\"\n",
        "        f\" AND hour >= {start_hour} AND hour <= {end_hour}\"\n",
        "        f\" AND lat >= {LAT_MIN} AND lat <= {LAT_MAX}\"\n",
        "        f\" AND lon>= {LON_MIN} AND lon <= {LON_MAX}\"\n",
        "        f\" AND geoaltitude >= {ALT_MIN} AND geoaltitude <= {ALT_MAX}\"\n",
        "        f\" ORDER BY time\"\n",
        "    )\n",
        "\n",
        "trino = Trino()\n",
        "\n",
        "svdata4_df = trino.query(\n",
        "    svdata4_query,\n",
        "    cached=False,\n",
        "    compress=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to OSN database...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "RUNNING: : 100% [00:07, 13.5%/s]\n",
            "DOWNLOAD: 2.99Mlines [02:25, 20.5klines/s]\n"
          ]
        }
      ],
      "source": [
        "icao_list = svdata4_df.icao24.unique()\n",
        "icao24_str = ', '.join(f\"'{item}'\" for item in icao_list)\n",
        "\n",
        "ops_sts_query = (\n",
        "    f\"SELECT icao24, mintime, maxtime, nacv, systemdesignassurance, version, positionnac, geometricverticalaccuracy, sourceintegritylevel, barometricaltitudeintegritycode  FROM operational_status_data4\"\n",
        "    f\" WHERE icao24 IN ({icao24_str})\"\n",
        "    f\" AND mintime >= {start_time} AND maxtime <= {end_time}\"\n",
        "    f\" AND hour >= {start_hour} AND hour <= {end_hour}\"\n",
        "    f\" ORDER by mintime\"\n",
        ")\n",
        "\n",
        "print('Connecting to OSN database...')\n",
        "trino = Trino()\n",
        "ops_sts_df = trino.query(\n",
        "    ops_sts_query,\n",
        "    cached=False,\n",
        ")\n",
        "\n",
        "ops_sts_df['time'] = ops_sts_df['mintime'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an empty DataFrame to hold the results\n",
        "merged_df = pd.DataFrame()\n",
        "\n",
        "# Loop over each unique 'icao24' in both dataframes\n",
        "unique_icao24s = pd.concat([svdata4_df['icao24'], ops_sts_df['icao24']]).unique()\n",
        "\n",
        "for icao24 in unique_icao24s:\n",
        "    # Filter each dataframe by 'icao24'\n",
        "    sub_df1 = svdata4_df[svdata4_df['icao24'] == icao24]\n",
        "    sub_df2 = ops_sts_df[ops_sts_df['icao24'] == icao24]\n",
        "\n",
        "    # Ensure both sub-dataframes are sorted by 'time'\n",
        "    sub_df1 = sub_df1.sort_values('time')\n",
        "    sub_df2 = sub_df2.sort_values('time')\n",
        "\n",
        "    # Perform merge_asof on the filtered and sorted dataframes\n",
        "    merged_sub_df = pd.merge_asof(sub_df1, sub_df2, on='time', by='icao24', direction='backward')\n",
        "    \n",
        "    # Append the result to the main dataframe\n",
        "    merged_df = pd.concat([merged_df, merged_sub_df], ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to OSN database...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "FINISHED: : 100% [00:02, 48.9%/s]\n",
            "DOWNLOAD: 117klines [00:00, 214klines/s]\n"
          ]
        }
      ],
      "source": [
        "posdata4_query = (\n",
        "    f\"SELECT mintime, icao24, nic  FROM position_data4\"\n",
        "    f\" WHERE icao24 IN ({icao24_str})\"\n",
        "    f\" AND lat >= {LAT_MIN} AND lat <= {LAT_MAX}\"\n",
        "    f\" AND lon>= {LON_MIN} AND lon <= {LON_MAX}\"\n",
        "    f\" AND mintime >= {start_time} AND maxtime <= {end_time}\"\n",
        "    f\" AND hour >= {start_hour} AND hour <= {end_hour}\"\n",
        "    f\" ORDER by mintime\"\n",
        ")\n",
        "\n",
        "print('Connecting to OSN database...')\n",
        "trino = Trino()\n",
        "posdata4_df = trino.query(\n",
        "    posdata4_query,\n",
        "    cached=False,\n",
        ")\n",
        "\n",
        "posdata4_df['time'] = posdata4_df['mintime'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize an empty DataFrame to hold the results\n",
        "final_df = pd.DataFrame()\n",
        "\n",
        "for icao24 in unique_icao24s:\n",
        "    # Filter each dataframe by 'icao24'\n",
        "    sub_df1 = merged_df[merged_df['icao24'] == icao24]\n",
        "    sub_df2 = posdata4_df[posdata4_df['icao24'] == icao24]\n",
        "\n",
        "    # Ensure both sub-dataframes are sorted by 'time'\n",
        "    sub_df1 = sub_df1.sort_values('time')\n",
        "    sub_df2 = sub_df2.sort_values('time')\n",
        "\n",
        "    # Perform merge_asof on the filtered and sorted dataframes\n",
        "    merged_sub_df = pd.merge_asof(sub_df1, sub_df2, on='time', by='icao24', direction='backward')\n",
        "    \n",
        "    # Append the result to the main dataframe\n",
        "    final_df = pd.concat([final_df, merged_sub_df], ignore_index=True)\n",
        "\n",
        "final_df = final_df.drop(columns=['hour', 'mintime_x', 'maxtime', 'mintime_y'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Add DEM ground elevation information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "crs_transformer = Transformer.from_crs(4326, 3035, always_xy = True) # Transformer from WGS-84 to ETRS89-LAEA\n",
        "\n",
        "def transform_coords(lon, lat):\n",
        "    return crs_transformer.transform(lon, lat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_df['gnd_elev'] = np.nan\n",
        "\n",
        "dem_src = rasterio.open('./resources/Cologne_EUDEM_v11.tif')\n",
        "\n",
        "final_df['etrs89_x'], final_df['etrs89_y'] = zip(*final_df.apply(lambda row: transform_coords(row['lon'], row['lat']), axis=1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_elevation(x, y, dem):\n",
        "    row, col = dem.index(x, y)\n",
        "    return dem.read(1)[row, col]\n",
        "\n",
        "final_df['gnd_elev'] = final_df.apply(lambda row: get_elevation(row['etrs89_x'], row['etrs89_y'], dem_src), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_df = final_df.drop(columns=['etrs89_x', 'etrs89_y'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Process df with distance information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "def haversine(pt1, pt2):\n",
        "    \"\"\"\n",
        "    Calculate the great circle distance between two points\n",
        "    on the earth (specified in decimal degrees)\n",
        "    Returned units are in metres. Differs slightly from PostGIS geography\n",
        "    distance, which uses a spheroid, rather than a sphere.\n",
        "    \"\"\"\n",
        "\n",
        "    lat1, lon1 = pt1[0], pt1[1]\n",
        "    lat2, lon2 = pt2[0], pt2[1]\n",
        "\n",
        "    # convert decimal degrees to radians\n",
        "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
        "\n",
        "    # haversine formula\n",
        "    dlon = lon2 - lon1\n",
        "    dlat = lat2 - lat1\n",
        "    a = sin(dlat / 2.0) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2.0) ** 2\n",
        "    c = 2 * asin(sqrt(a))\n",
        "    r = 6371000  # Radius of earth in m\n",
        "    return c * r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_df[\"prev_time\"] = final_df.time.shift()\n",
        "final_df['closest_obst_name'] = 'ground'\n",
        "final_df['inf_flt'] = False\n",
        "final_df['inf_pt'] = False\n",
        "final_df['gnd_inf_flt'] = False\n",
        "final_df['gnd_inf_pt'] = False\n",
        "final_df['min_hgt'] = final_df['gnd_elev'] + 300 # Minimum height away from obstacles is 300 m above ground (over congested areas)\n",
        "\n",
        "map_time_traj = defaultdict(dict)\n",
        "\n",
        "for icao, sfinal_df in final_df.groupby(\"icao24\"):\n",
        "    map_time_traj[icao][sfinal_df.iloc[0][\"time\"]] = icao + \"_1\"\n",
        "    n_traj = 1\n",
        "    for i in range(1, sfinal_df.shape[0]):\n",
        "        time = sfinal_df.iloc[i][\"time\"]\n",
        "        diff = abs(int(time) - int(sfinal_df.iloc[i][\"prev_time\"]))\n",
        "        if diff > TIME_BETWEEN_TRAJS:\n",
        "            n_traj += 1\n",
        "        map_time_traj[icao][time] = icao + \"_\" + str(int(n_traj))\n",
        "\n",
        "final_df['ref'] = final_df.apply(lambda x: map_time_traj[x.icao24][x.time], axis=1) + '_' + final_df.time.apply(lambda x: pd.to_datetime(x, unit='s').strftime(\"%d%m%y\"))\n",
        "\n",
        "# Add a distance column and compute cumulative along-track distance for each flight\n",
        "final_df['dist'] = 0.0\n",
        "for flight in final_df.ref.unique():\n",
        "  first = True\n",
        "  current = final_df[final_df['ref'].isin([flight])] # gets the trajectory of the current flight\n",
        "  for row in current.itertuples():\n",
        "    if not(first):\n",
        "      current_pt = (float(row.lat), float(row.lon))\n",
        "      delta_dist = haversine(previous_pt, current_pt)\n",
        "      final_df.loc[row[0],'dist'] = previous_dist + delta_dist\n",
        "    previous_pt = (float(row.lat), float(row.lon))\n",
        "    previous_dist = final_df.loc[row[0],'dist']\n",
        "    first = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load obstacle information and check min height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_to_obstacles_json = './resources/obstacles.json'\n",
        "\n",
        "with open(path_to_obstacles_json) as obstacles_database:\n",
        "    obstacles_data = json.load(obstacles_database)\n",
        "obs_df = pd.json_normalize(obstacles_data, record_path =['obstacles'])\n",
        "\n",
        "obs_df['etrs89_x'], obs_df['etrs89_y'] = zip(*obs_df.apply(lambda row: transform_coords(row['lon'], row['lat']), axis=1))\n",
        "obs_df['gnd_elev'] = obs_df.apply(lambda row: get_elevation(row['etrs89_x'], row['etrs89_y'], dem_src), axis=1)\n",
        "obs_df = obs_df.drop(columns=['etrs89_x', 'etrs89_y'])\n",
        "\n",
        "obs_df = obs_df.sort_values(by=['height_m']) # sort obstacles by incresing height, to avoid that the min_hgt profil is wrong if a shorter obstacle comes after a taller one, in case the aircraft is within two obstacles clearance areas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_closest_obstacle(final_df, obstacles_df, radius):\n",
        "    # Iterate over each point in the final_df\n",
        "    for index, row in final_df.iterrows():\n",
        "        point = (row['lat'], row['lon'])\n",
        "        \n",
        "        # Filter obstacles within the given radius\n",
        "        obstacles_within_radius = obstacles_df[\n",
        "            obstacles_df.apply(lambda obs: haversine(point, (obs['lat'], obs['lon'])) <= radius, axis=1)\n",
        "        ]\n",
        "        \n",
        "        # If there are any obstacles within the radius, find the tallest one\n",
        "        if not obstacles_within_radius.empty:\n",
        "            tallest_obstacle = obstacles_within_radius.loc[obstacles_within_radius['height_m'].idxmax()]\n",
        "            final_df.at[index, 'closest_obst_name'] = tallest_obstacle['name']\n",
        "            final_df.at[index, 'min_hgt'] = GEOID_HEIGHT_M + np.float32(tallest_obstacle['gnd_elev']) + np.float32(tallest_obstacle['height_m']) + ALERT_DELTA_HEIGHT_M\n",
        "\n",
        "    return final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {},
      "outputs": [],
      "source": [
        "final_df = update_closest_obstacle(final_df, obs_df, 600)\n",
        "\n",
        "final_df['dip'] = final_df['min_hgt'] - final_df['geoaltitude']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {},
      "outputs": [],
      "source": [
        "rhein_coords = [[6.975930879168959,50.95657408794192],\n",
        "[6.972535124899244,50.95458641663587],\n",
        "[6.967809452697489,50.95085449055784],\n",
        "[6.964303258235203,50.94648787705209],\n",
        "[6.962946874051212,50.94281719236779],\n",
        "[6.96352513940893,50.93620396292537],\n",
        "[6.965306071776009,50.93028081346332],\n",
        "[6.969701292329919,50.91962775943225],\n",
        "[6.974670336848934,50.91147192727765],\n",
        "[6.979500669602354,50.90559075596518],\n",
        "[6.988910832741286,50.89811010115705],\n",
        "[7.001299970098163,50.89290819036373],\n",
        "[7.011608685904386,50.89253183470269],\n",
        "[7.013331310567981,50.89615626376607],\n",
        "[7.001160198607601,50.89750937089659],\n",
        "[6.991533142700823,50.90103254802452],\n",
        "[6.988667339298418,50.90270433843045],\n",
        "[6.983479655838492,50.90851708398598],\n",
        "[6.975279465952471,50.91906362354751],\n",
        "[6.970153101800916,50.93012572612207],\n",
        "[6.970658769054046,50.93156686745481],\n",
        "[6.968078026948048,50.93770005507804],\n",
        "[6.968636570741024,50.94353672207991],\n",
        "[6.972110561853963,50.94977637503464],\n",
        "[6.978430041779998,50.95436079405016],\n",
        "[6.984223870632302,50.9521389418798],\n",
        "[6.994914076799508,50.95996315483612],\n",
        "[6.997507875246713,50.96355172063916],\n",
        "[6.993574311759938,50.96491142024293],\n",
        "[6.975930879168959,50.95657408794192]]\n",
        "\n",
        "rhein_polygon = Polygon(rhein_coords)\n",
        "\n",
        "points = gpd.GeoSeries([Point(xy) for xy in zip(final_df['lon'], final_df['lat'])])\n",
        "\n",
        "final_df['in_rhein'] = points.within(rhein_polygon)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Add infraction information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rule for 'inf_pt'\n",
        "final_df['inf_pt'] = final_df.apply(\n",
        "    lambda row: True if row['dip'] > 0 and not row['in_rhein'] and row['closest_obst_name'] != 'ground' else False,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Rule for 'gnd_inf_pt'\n",
        "final_df['gnd_inf_pt'] = final_df.apply(\n",
        "    lambda row: True if (row['dip'] > 0 and row['closest_obst_name'] == 'ground') or \n",
        "                ((GEOID_HEIGHT_M + row['gnd_elev'] + ALERT_DELTA_HEIGHT_M - row['geoaltitude']) > 0) else False,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Group by 'ref' and update 'inf_flt' based on 'inf_pt'\n",
        "final_df['inf_flt'] = final_df.groupby('ref')['inf_pt'].transform('any')\n",
        "\n",
        "# Group by 'ref' and update 'gnd_inf_flt' based on 'gnd_inf_pt'\n",
        "final_df['gnd_inf_flt'] = final_df.groupby('ref')['gnd_inf_pt'].transform('any')\n",
        "\n",
        "final_df = final_df.drop(columns=['serials', 'nacv'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "connected\n",
            "step 1\n",
            "Done\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Distant data for tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "connected\n"
          ]
        }
      ],
      "source": [
        "with sshtunnel.SSHTunnelForwarder(\n",
        "    (MYSQL_creds['SSH_ADDRESS']),\n",
        "    ssh_username = MYSQL_creds['SSH_USERNAME'], ssh_password = MYSQL_creds['SSH_PASSWORD'],\n",
        "    remote_bind_address = (MYSQL_creds['REMOTE_BIND_ADDRESS'], MYSQL_creds['REMOTE_BIND_PORT'])\n",
        ") as tunnel:\n",
        "    print('connected')\n",
        "\n",
        "    engstr =  'mysql+pymysql://' + MYSQL_creds['SSH_USERNAME'] + ':' + MYSQL_creds['PYANYWHERE_PASSWORD'] + '@127.0.0.1:' + str(tunnel.local_bind_port)+'/dme3$' + MYSQL_creds['TEST_DATABASE_NAME']\n",
        "\n",
        "    engine = create_engine(engstr)\n",
        "\n",
        "    sql_query = \"\"\"\n",
        "    SELECT ref, lat, lon \n",
        "    FROM main_data_test\n",
        "    WHERE positionnac >= 8\n",
        "    \"\"\"\n",
        "    \n",
        "    distant_df = pd.read_sql(sql_query, con=engine)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ref</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3df741_1_010724</td>\n",
              "      <td>50.966740</td>\n",
              "      <td>6.948318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3df741_1_010724</td>\n",
              "      <td>50.966414</td>\n",
              "      <td>6.948471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3df741_1_010724</td>\n",
              "      <td>50.965988</td>\n",
              "      <td>6.948630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3df741_1_010724</td>\n",
              "      <td>50.965530</td>\n",
              "      <td>6.948853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3df741_1_010724</td>\n",
              "      <td>50.965118</td>\n",
              "      <td>6.949075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45630</th>\n",
              "      <td>3d257e_2_310724</td>\n",
              "      <td>50.911622</td>\n",
              "      <td>6.921387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45631</th>\n",
              "      <td>3d257e_2_310724</td>\n",
              "      <td>50.912155</td>\n",
              "      <td>6.921090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45632</th>\n",
              "      <td>3d257e_2_310724</td>\n",
              "      <td>50.912659</td>\n",
              "      <td>6.920793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45633</th>\n",
              "      <td>3d257e_2_310724</td>\n",
              "      <td>50.913254</td>\n",
              "      <td>6.920422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45634</th>\n",
              "      <td>3d257e_2_310724</td>\n",
              "      <td>50.913757</td>\n",
              "      <td>6.920125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>45635 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   ref        lat       lon\n",
              "0      3df741_1_010724  50.966740  6.948318\n",
              "1      3df741_1_010724  50.966414  6.948471\n",
              "2      3df741_1_010724  50.965988  6.948630\n",
              "3      3df741_1_010724  50.965530  6.948853\n",
              "4      3df741_1_010724  50.965118  6.949075\n",
              "...                ...        ...       ...\n",
              "45630  3d257e_2_310724  50.911622  6.921387\n",
              "45631  3d257e_2_310724  50.912155  6.921090\n",
              "45632  3d257e_2_310724  50.912659  6.920793\n",
              "45633  3d257e_2_310724  50.913254  6.920422\n",
              "45634  3d257e_2_310724  50.913757  6.920125\n",
              "\n",
              "[45635 rows x 3 columns]"
            ]
          },
          "execution_count": 222,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "distant_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create infraction tables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {},
      "outputs": [],
      "source": [
        "inf_pt_df = final_df[final_df.inf_pt]\n",
        "\n",
        "lat, lon = obs_df.loc[obs_df['name'] == 'Ringturm', ['lat', 'lon']].values[0]\n",
        "\n",
        "inf_pt_df['dist_to_obs'] = np.nan\n",
        "\n",
        "inf_pt_df['dist_to_obs'] = inf_pt_df.apply(\n",
        "    lambda x: haversine(\n",
        "            (obs_df.loc[obs_df['name'] == x['closest_obst_name'], 'lat'].iloc[0],\n",
        "            obs_df.loc[obs_df['name'] == x['closest_obst_name'], 'lon'].iloc[0]),\n",
        "            (x['lat'], x['lon'])\n",
        "    ) if not (x['closest_obst_name'] == 'ground') else np.nan, \n",
        "    axis=1\n",
        ")\n",
        "\n",
        "inf_pt_df['time'] = pd.to_datetime(inf_pt_df['time'], unit='s')\n",
        "inf_pt_df = inf_pt_df.sort_values(by=['ref', 'closest_obst_name', 'time'])\n",
        "\n",
        "inf_pt_df['time_diff'] = inf_pt_df.groupby(['ref', 'closest_obst_name'])['time'].diff()\n",
        "inf_pt_df['group'] = (inf_pt_df['time_diff'] >= pd.Timedelta(seconds=30)).cumsum()\n",
        "\n",
        "inf_grouped = inf_pt_df.groupby(['ref', 'closest_obst_name', 'group'])\n",
        "\n",
        "inf_min_dist = inf_grouped.apply(lambda x: x.loc[x['dist_to_obs'].idxmin()]).reset_index(drop=True)\n",
        "inf_max_dip = inf_grouped['dip'].max().reset_index()\n",
        "\n",
        "inf_result = inf_min_dist[['icao24', 'callsign', 'group', 'ref', 'closest_obst_name', 'time', 'lat', 'lon', 'dist_to_obs']].copy()\n",
        "inf_result = inf_result.merge(inf_max_dip, on=['ref', 'closest_obst_name', 'group'])\n",
        "\n",
        "inf_result.rename(columns={'dist_to_obs': 'cpa', 'dip': 'max_dip'}, inplace=True)\n",
        "\n",
        "inf_result['entry_count'] = inf_result.groupby('ref').cumcount()\n",
        "inf_result['unique_ref'] = inf_result['ref'].astype(str) + '_' + inf_result['entry_count'].astype(str)\n",
        "\n",
        "\n",
        "inf_result['url'] = inf_result.apply(lambda row: \"https://globe.adsbexchange.com/?icao=%s&lat=50.928&lon=6.947&zoom=13.2&showTrace=%s&timestamp=%s\" % (\n",
        "    row['icao24'],\n",
        "    row['time'].strftime('%Y-%m-%d'),\n",
        "    str(int(row['time'].timestamp()))\n",
        "), axis=1)\n",
        "\n",
        "inf_result = inf_result.reset_index(drop=True)\n",
        "\n",
        "inf_result = inf_result.drop(columns=['entry_count'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ground infractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {},
      "outputs": [],
      "source": [
        "gnd_inf_pt_df = final_df[final_df.gnd_inf_pt & (final_df.dip >= 0) & (final_df.closest_obst_name == 'ground')]\n",
        "\n",
        "gnd_inf_pt_df['time'] = pd.to_datetime(gnd_inf_pt_df['time'], unit='s')\n",
        "gnd_inf_pt_df = gnd_inf_pt_df.sort_values(by=['ref', 'time'])\n",
        "\n",
        "gnd_inf_pt_df['time_diff'] = gnd_inf_pt_df.groupby(['ref'])['time'].diff()\n",
        "gnd_inf_pt_df['group'] = (gnd_inf_pt_df['time_diff'] >= pd.Timedelta(seconds=30)).cumsum()\n",
        "\n",
        "gnd_inf_grouped = gnd_inf_pt_df.groupby(['ref', 'group'])\n",
        "\n",
        "gnd_inf_max_dip = gnd_inf_grouped.apply(lambda x: x.loc[x['dip'].idxmax()]).reset_index(drop=True)\n",
        "\n",
        "gnd_inf_result = gnd_inf_max_dip[['icao24', 'callsign', 'group', 'ref', 'closest_obst_name', 'time', 'lat', 'lon', 'dip']].copy()\n",
        "\n",
        "gnd_inf_result.rename(columns={'dip': 'max_dip'}, inplace=True)\n",
        "\n",
        "gnd_inf_result['entry_count'] = gnd_inf_result.groupby('ref').cumcount()\n",
        "gnd_inf_result['unique_ref'] = gnd_inf_result['ref'].astype(str) + '_' + 'gnd_' + gnd_inf_result['entry_count'].astype(str)\n",
        "\n",
        "gnd_inf_result['url'] = gnd_inf_result.apply(lambda row: \"https://globe.adsbexchange.com/?icao=%s&lat=50.928&lon=6.947&zoom=13.2&showTrace=%s&timestamp=%s\" % (\n",
        "    row['icao24'],\n",
        "    row['time'].strftime('%Y-%m-%d'),\n",
        "    str(int(row['time'].timestamp()))\n",
        "), axis=1)\n",
        "\n",
        "gnd_inf_result = gnd_inf_result.reset_index(drop=True)\n",
        "\n",
        "gnd_inf_result = gnd_inf_result.drop(columns=['entry_count'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Upload data to MySQL server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "connected\n",
            "step 1\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "with sshtunnel.SSHTunnelForwarder(\n",
        "    (MYSQL_creds['SSH_ADDRESS']),\n",
        "    ssh_username = MYSQL_creds['SSH_USERNAME'], ssh_password = MYSQL_creds['SSH_PASSWORD'],\n",
        "    remote_bind_address = (MYSQL_creds['REMOTE_BIND_ADDRESS'], MYSQL_creds['REMOTE_BIND_PORT'])\n",
        ") as tunnel:\n",
        "    print('connected')\n",
        "\n",
        "    engstr =  'mysql+pymysql://' + MYSQL_creds['SSH_USERNAME'] + ':' + MYSQL_creds['PYANYWHERE_PASSWORD'] + '@127.0.0.1:' + str(tunnel.local_bind_port)+'/dme3$' + MYSQL_creds['TEST_DATABASE_NAME']\n",
        "\n",
        "    engine = create_engine(engstr)\n",
        "\n",
        "    print('step 1')\n",
        "    \n",
        "    final_df.to_sql(con=engine, name = MYSQL_creds['MAIN_TEST_TABLE_NAME'], if_exists='replace')\n",
        "    inf_result.to_sql(con=engine, name = MYSQL_creds['INF_TEST_TABLE_NAME'], if_exists='replace')\n",
        "    gnd_inf_result.to_sql(con=engine, name = MYSQL_creds['GNDINF_TEST_TABLE_NAME'], if_exists='replace')\n",
        "\n",
        "\n",
        "    print(\"Done\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
